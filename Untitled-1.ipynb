{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/xdg-ubuntu/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/dhruv/.config/sagemaker/config.yaml\n",
      "Using bucket ticketresolution\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "\n",
    "import json\n",
    "with open('aws_config.json', 'r') as f:\n",
    "    aws_config = json.load(f)\n",
    "\n",
    "sm_boto3 = boto3.client(\n",
    "    **aws_config\n",
    ")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = \"ticketresolution\"\n",
    "print(\"Using bucket \" + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = sess.upload_data(\n",
    "    path=\"train.csv\",\n",
    "    bucket=bucket,\n",
    "    key_prefix=\"training_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/xdg-ubuntu/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/dhruv/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"uci-newsaggregator\"\n",
    "\n",
    "role = \"arn:aws:iam::211125521046:role/SageRole\"\n",
    "# role = \"arn:aws:servicequotas:ap-southeast-2:211125521046:sagemaker/L-EA346344\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mPyTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mentry_point\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipelineVariable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mframework_version\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpy_version\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msource_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipelineVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhyperparameters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipelineVariable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mimage_uri\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipelineVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdistribution\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompiler_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingCompilerConfig\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      Handle end-to-end training and deployment of custom PyTorch code.\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "This ``Estimator`` executes a PyTorch script in a managed PyTorch execution environment.\n",
      "\n",
      "The managed PyTorch environment is an Amazon-built Docker container that executes functions\n",
      "defined in the supplied ``entry_point`` Python script within a SageMaker Training Job.\n",
      "\n",
      "Training is started by calling\n",
      ":meth:`~sagemaker.amazon.estimator.Framework.fit` on this Estimator.\n",
      "After training is complete, calling\n",
      ":meth:`~sagemaker.amazon.estimator.Framework.deploy` creates a hosted\n",
      "SageMaker endpoint and returns an\n",
      ":class:`~sagemaker.amazon.pytorch.model.PyTorchPredictor` instance that\n",
      "can be used to perform inference against the hosted model.\n",
      "\n",
      "Technical documentation on preparing PyTorch scripts for SageMaker\n",
      "training and using the PyTorch Estimator is available on the project\n",
      "home-page: https://github.com/aws/sagemaker-python-sdk\n",
      "\n",
      "Args:\n",
      "    entry_point (str or PipelineVariable): Path (absolute or relative) to the\n",
      "        Python source file which should be executed as the entry point to training.\n",
      "        If ``source_dir`` is specified, then ``entry_point``\n",
      "        must point to a file located at the root of ``source_dir``.\n",
      "    framework_version (str): PyTorch version you want to use for\n",
      "        executing your model training code. Defaults to ``None``. Required unless\n",
      "        ``image_uri`` is provided. List of supported versions:\n",
      "        https://github.com/aws/deep-learning-containers/blob/master/available_images.md.\n",
      "    py_version (str): Python version you want to use for executing your\n",
      "        model training code. One of 'py2' or 'py3'. Defaults to ``None``. Required\n",
      "        unless ``image_uri`` is provided.\n",
      "    source_dir (str or PipelineVariable): Path (absolute, relative or an S3 URI) to\n",
      "        a directory with any other training source code dependencies aside from the entry\n",
      "        point file (default: None). If ``source_dir`` is an S3 URI, it must\n",
      "        point to a tar.gz file. Structure within this directory are preserved\n",
      "        when training on Amazon SageMaker.\n",
      "    hyperparameters (dict[str, str] or dict[str, PipelineVariable]): Hyperparameters\n",
      "        that will be used for training (default: None). The hyperparameters are made\n",
      "        accessible as a dict[str, str] to the training code on\n",
      "        SageMaker. For convenience, this accepts other types for keys\n",
      "        and values, but ``str()`` will be called to convert them before\n",
      "        training.\n",
      "    image_uri (str or PipelineVariable): If specified, the estimator will use this image\n",
      "        for training and hosting, instead of selecting the appropriate\n",
      "        SageMaker official image based on framework_version and\n",
      "        py_version. It can be an ECR url or dockerhub image and tag.\n",
      "        Examples:\n",
      "            * ``123412341234.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0``\n",
      "            * ``custom-image:latest``\n",
      "\n",
      "        If ``framework_version`` or ``py_version`` are ``None``, then\n",
      "        ``image_uri`` is required. If also ``None``, then a ``ValueError``\n",
      "        will be raised.\n",
      "    distribution (dict): A dictionary with information on how to configure and\n",
      "        run distributed training\n",
      "        (default: None). The following options are available.\n",
      "\n",
      "        **To enable the SageMaker distributed data parallelism (SMDDP) library:**\n",
      "\n",
      "            .. code:: python\n",
      "\n",
      "                { \"smdistributed\": { \"dataparallel\": { \"enabled\": True } } }\n",
      "\n",
      "            Beside activating the SMDDP library through this parameter,\n",
      "            you also need to add few lines of code in your training script\n",
      "            for initializing PyTorch Distributed with the SMDDP setups.\n",
      "            To learn how to configure your training job with the SMDDP library v2, see\n",
      "            `Run distributed training with the SageMaker distributed data parallelism\n",
      "            library\n",
      "            <https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html>`_\n",
      "            in the *Amazon SageMaker User Guide*.\n",
      "\n",
      "        **To enable the SageMaker distributed model parallelism (SMP) library v2:**\n",
      "\n",
      "            .. code:: python\n",
      "\n",
      "                {\n",
      "                    \"torch_distributed\": { \"enabled\": True },\n",
      "                    \"smdistributed\": {\n",
      "                        \"modelparallel\": {\n",
      "                            \"enabled\": True,\n",
      "                            \"parameters\": {\n",
      "                                \"tensor_parallel_degree\": 8,\n",
      "                                \"hybrid_shard_degree\": 1,\n",
      "                                ...\n",
      "                            },\n",
      "                        }\n",
      "                    },\n",
      "                }\n",
      "\n",
      "            Beside activating the SMP library v2 through this parameter,\n",
      "            you also need to add few lines of code in your training script\n",
      "            for initializing PyTorch Distributed with the SMP setups.\n",
      "            To learn how to configure your training job with the SMP library v2, see\n",
      "            `Run distributed training with the SageMaker model parallelism library v2\n",
      "            <https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-v2.html>`_\n",
      "            in the *Amazon SageMaker User Guide*.\n",
      "\n",
      "            .. note::\n",
      "\n",
      "                The SageMaker distributed model parallel library v2 requires with\n",
      "                ``torch_distributed``.\n",
      "\n",
      "            .. note::\n",
      "\n",
      "                The documentation for the SMP library v1.x is archived and available at\n",
      "                `Run distributed training with the SageMaker model parallelism library\n",
      "                <https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel.html>`_\n",
      "                in the *Amazon SageMaker User Guide*,\n",
      "                and the SMP v1 API reference is available in the\n",
      "                `SageMaker Python SDK v2.199.0 documentation\n",
      "                <https://sagemaker.readthedocs.io/en/v2.199.0/api/training/distributed.html#the-sagemaker-distributed-model-parallel-library>`_.\n",
      "\n",
      "        **To enable PyTorch DDP:**\n",
      "\n",
      "            .. code:: python\n",
      "\n",
      "                {\n",
      "                    \"pytorchddp\": {\n",
      "                        \"enabled\": True\n",
      "                    }\n",
      "                }\n",
      "\n",
      "            To learn more, see `Distributed PyTorch Training\n",
      "            <https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#distributed-pytorch-training>`_.\n",
      "\n",
      "        **To enable Torch Distributed:**\n",
      "\n",
      "            This is available for general distributed training on\n",
      "            GPU instances from PyTorch v1.13.1 and later.\n",
      "\n",
      "            .. code:: python\n",
      "\n",
      "                {\n",
      "                    \"torch_distributed\": {\n",
      "                        \"enabled\": True\n",
      "                    }\n",
      "                }\n",
      "\n",
      "            This option also supports distributed training on Trn1.\n",
      "            To learn more, see `Distributed PyTorch Training on Trainium\n",
      "            <https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#distributed-pytorch-training-on-trainium>`_.\n",
      "\n",
      "        **To enable MPI:**\n",
      "\n",
      "            .. code:: python\n",
      "\n",
      "                {\n",
      "                    \"mpi\": {\n",
      "                        \"enabled\": True\n",
      "                    }\n",
      "                }\n",
      "\n",
      "            To learn more, see `Training with Horovod\n",
      "            <https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#training-with-horovod>`_.\n",
      "\n",
      "        **To enable parameter server:**\n",
      "\n",
      "            .. code:: python\n",
      "\n",
      "                {\n",
      "                    \"parameter_server\": {\n",
      "                        \"enabled\": True\n",
      "                    }\n",
      "                }\n",
      "\n",
      "            To learn more, see `Training with parameter servers\n",
      "            <https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#training-with-parameter-servers>`_.\n",
      "\n",
      "        **To enable distributed training with SageMaker Training Compiler:**\n",
      "\n",
      "            .. code:: python\n",
      "\n",
      "                {\n",
      "                    \"pytorchxla\": {\n",
      "                        \"enabled\": True\n",
      "                    }\n",
      "                }\n",
      "\n",
      "            To learn more, see `SageMaker Training Compiler\n",
      "            <https://docs.aws.amazon.com/sagemaker/latest/dg/training-compiler.html>`_\n",
      "            in the *Amazon SageMaker Developer Guide*.\n",
      "\n",
      "            .. note::\n",
      "\n",
      "                When you use this PyTorch XLA option for distributed training strategy,\n",
      "                you must add the ``compiler_config`` parameter and activate SageMaker\n",
      "                Training Compiler.\n",
      "\n",
      "        compiler_config (:class:`~sagemaker.pytorch.TrainingCompilerConfig`):\n",
      "        Configures SageMaker Training Compiler to accelerate training.\n",
      "\n",
      "    **kwargs: Additional kwargs passed to the :class:`~sagemaker.estimator.Framework`\n",
      "        constructor.\n",
      "\n",
      ".. tip::\n",
      "\n",
      "    You can find additional parameters for initializing this class at\n",
      "    :class:`~sagemaker.estimator.Framework` and\n",
      "    :class:`~sagemaker.estimator.EstimatorBase`.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/pytorch/estimator.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyTorch\n\u001b[1;32m      3\u001b[0m estimator \u001b[38;5;241m=\u001b[39m PyTorch(\n\u001b[1;32m      4\u001b[0m     entry_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     dependencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./requirements.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/estimator.py:1335\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;129m@runnable_by_pipeline\u001b[39m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     experiment_config: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1278\u001b[0m ):\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a model using the input training dataset.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[1;32m   1281\u001b[0m \u001b[38;5;124;03m    The API calls the Amazon SageMaker CreateTrainingJob API to start\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;124;03m        :class:`~sagemaker.workflow.pipeline_context.PipelineSession`\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1337\u001b[0m     experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job \u001b[38;5;241m=\u001b[39m _TrainingJob\u001b[38;5;241m.\u001b[39mstart_new(\u001b[38;5;28mself\u001b[39m, inputs, experiment_config)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/estimator.py:3515\u001b[0m, in \u001b[0;36mFramework._prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m   3507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_for_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3508\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set hyperparameters needed for training. This method will also validate ``source_dir``.\u001b[39;00m\n\u001b[1;32m   3509\u001b[0m \n\u001b[1;32m   3510\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;124;03m            constructor if applicable.\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3515\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFramework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3517\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_set_debugger_configs()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/estimator.py:933\u001b[0m, in \u001b[0;36mEstimatorBase._prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muploaded_code\u001b[38;5;241m.\u001b[39ms3_prefix\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 933\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muploaded_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stage_user_code_in_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m     code_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muploaded_code\u001b[38;5;241m.\u001b[39ms3_prefix\n\u001b[1;32m    935\u001b[0m     script \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muploaded_code\u001b[38;5;241m.\u001b[39mscript_name\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/estimator.py:1015\u001b[0m, in \u001b[0;36mEstimatorBase._stage_user_code_in_s3\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             output_bucket, _ \u001b[38;5;241m=\u001b[39m parse_s3_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_path)\n\u001b[1;32m   1013\u001b[0m             kms_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_kms_key \u001b[38;5;28;01mif\u001b[39;00m code_bucket \u001b[38;5;241m==\u001b[39m output_bucket \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtar_and_upload_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboto_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_bucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_s3_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscript\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdependencies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms3_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/fw_utils.py:472\u001b[0m, in \u001b[0;36mtar_and_upload_dir\u001b[0;34m(session, bucket, s3_key_prefix, script, directory, dependencies, kms_key, s3_resource, settings)\u001b[0m\n\u001b[1;32m    469\u001b[0m encrypt_artifact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m settings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mencrypt_repacked_artifacts\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 472\u001b[0m     source_files \u001b[38;5;241m=\u001b[39m \u001b[43m_list_files_to_compress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdependencies\u001b[49m\n\u001b[1;32m    473\u001b[0m     tar_file \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcreate_tar_file(\n\u001b[1;32m    474\u001b[0m         source_files, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmp, _TAR_SOURCE_FILENAME)\n\u001b[1;32m    475\u001b[0m     )\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kms_key:\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"main.py\",\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.11.0\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\"},\n",
    "    dependencies = \"./requirements.txt\"\n",
    ")\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2024-04-16-13-14-50-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-16 13:14:55 Starting - Starting the training job...\n",
      "2024-04-16 13:15:10 Starting - Preparing the instances for training......\n",
      "2024-04-16 13:16:28 Downloading - Downloading the training image..................\n",
      "2024-04-16 13:19:44 Training - Training image download completed. Training in progress..bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-04-16 13:19:55,226 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-04-16 13:19:55,253 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-04-16 13:19:55,264 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-04-16 13:19:55,268 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-04-16 13:19:56,485 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-04-16 13:19:56,536 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-04-16 13:19:56,581 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-04-16 13:19:56,598 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"model_name\": \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\",\n",
      "        \"train_batch_size\": 32\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2024-04-16-13-14-50-140\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-2-211125521046/huggingface-pytorch-training-2024-04-16-13-14-50-140/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"epochs\":1,\"model_name\":\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\",\"train_batch_size\":32}\n",
      "SM_USER_ENTRY_POINT=main.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=main\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=4\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-ap-southeast-2-211125521046/huggingface-pytorch-training-2024-04-16-13-14-50-140/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\",\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2024-04-16-13-14-50-140\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-2-211125521046/huggingface-pytorch-training-2024-04-16-13-14-50-140/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main.py\"}\n",
      "SM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\",\"--train_batch_size\",\"32\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_HP_EPOCHS=1\n",
      "SM_HP_MODEL_NAME=mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\n",
      "SM_HP_TRAIN_BATCH_SIZE=32\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.9 main.py --epochs 1 --model_name mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis --train_batch_size 32\n",
      "2024-04-16 13:19:56,628 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Initializing dataset generator class\n",
      "Creating model class\n",
      "Setting model training parameters\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/main.py\", line 128, in <module>\n",
      "train_df = pd.read_csv(\"train.csv\")\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 912, in read_csv\n",
      "return _read(filepath_or_buffer, kwds)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 577, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1407, in __init__\n",
      "self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1661, in _make_engine\n",
      "self.handles = get_handle(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\", line 859, in get_handle\n",
      "handle = open(\n",
      "FileNotFoundError\n",
      ": [Errno 2] No such file or directory: 'train.csv'\n",
      "2024-04-16 13:19:59,054 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-04-16 13:19:59,054 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\n",
      "2024-04-16 13:19:59,055 sagemaker-training-toolkit ERROR    Reporting training FAILURE\n",
      "2024-04-16 13:19:59,055 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\n",
      "ExitCode 1\n",
      "ErrorMessage \"FileNotFoundError\n",
      " [Errno 2] No such file or directory: 'train.csv'\"\n",
      "Command \"/opt/conda/bin/python3.9 main.py --epochs 1 --model_name mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis --train_batch_size 32\"\n",
      "2024-04-16 13:19:59,055 sagemaker-training-toolkit ERROR    Encountered exit_code 1\n",
      "\n",
      "2024-04-16 13:20:16 Uploading - Uploading generated training model\n",
      "2024-04-16 13:20:16 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m      3\u001b[0m hyperparameters\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,                                       \u001b[38;5;66;03m# number of training epochs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m32\u001b[39m,                            \u001b[38;5;66;03m# training batch size\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# name of pretrained model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      9\u001b[0m huggingface_estimator \u001b[38;5;241m=\u001b[39m HuggingFace(\n\u001b[1;32m     10\u001b[0m     entry_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,                 \u001b[38;5;66;03m# fine-tuning script to use in training job\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# source_dir=\"./scripts\",                 # directory where fine-tuning script is stored\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     hyperparameters\u001b[38;5;241m=\u001b[39mhyperparameters         \u001b[38;5;66;03m# hyperparameters to use in training job\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m \u001b[43mhuggingface_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/estimator.py:1341\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/estimator.py:2680\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2680\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/session.py:5760\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5740\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5741\u001b[0m \n\u001b[1;32m   5742\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5758\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5759\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5760\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/session.py:7939\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   7936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE:\n\u001b[1;32m   7937\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 7939\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE:\n\u001b[1;32m   7942\u001b[0m     state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "hyperparameters={\n",
    "    \"epochs\": 1,                                       # number of training epochs\n",
    "    \"train_batch_size\": 32,                            # training batch size\n",
    "    \"model_name\":\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\"  # name of pretrained model\n",
    "}\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=\"main.py\",                 # fine-tuning script to use in training job\n",
    "    # source_dir=\"./scripts\",                 # directory where fine-tuning script is stored\n",
    "    instance_type=\"ml.g4dn.xlarge\",          # instance type\n",
    "    instance_count=1,                       # number of instances\n",
    "    role=role,                              # IAM role used in training job to acccess AWS resources (S3)\n",
    "    transformers_version=\"4.26\",             # Transformers version\n",
    "    pytorch_version=\"1.13\",                  # PyTorch version\n",
    "    py_version=\"py39\",                      # Python version\n",
    "    hyperparameters=hyperparameters         # hyperparameters to use in training job\n",
    ")\n",
    "\n",
    "huggingface_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2024-04-15-22-11-09-195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15 22:11:11 Starting - Starting the training job."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/estimator.py:1341\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/estimator.py:2680\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2680\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/session.py:5760\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5740\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5741\u001b[0m \n\u001b[1;32m   5742\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5758\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5759\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5760\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/SageMaker-rvT5MvuP/lib/python3.10/site-packages/sagemaker/session.py:7939\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   7936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE:\n\u001b[1;32m   7937\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 7939\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE:\n\u001b[1;32m   7942\u001b[0m     state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mCOMPLETE\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMaker-rvT5MvuP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
